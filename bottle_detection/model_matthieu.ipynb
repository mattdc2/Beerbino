{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation des dossiers de stockage des images pour faire apparaitre leur label"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:model.ipynb
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_scrapping</th>\n",
       "      <th>link_photo</th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>type</th>\n",
       "      <th>website</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://media.auchan.fr/MEDIASTEP80202553_230x...</td>\n",
       "      <td>Bière blonde 11,8% boîte</td>\n",
       "      <td>BELZEBUTH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auchan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://media.auchan.fr/MEDIASTEP157309628_230...</td>\n",
       "      <td>Bière blonde bio 7.2% bouteilles</td>\n",
       "      <td>LA GOUDALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auchan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://media.auchan.fr/MEDIASTEP66806491_230x...</td>\n",
       "      <td>Bière blonde triple 8% bouteille</td>\n",
       "      <td>SECRET DES MOINES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auchan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://media.auchan.fr/MEDIASTEP137932992_230...</td>\n",
       "      <td>Bière brassin de Noël 6,5% bouteilles</td>\n",
       "      <td>GRIMBERGEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auchan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://media.auchan.fr/MEDIASTEP157260428_230...</td>\n",
       "      <td>Bière blonde triple signature 8.5%</td>\n",
       "      <td>CH'TI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Auchan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>737</td>\n",
       "      <td>https://d33za54wpumlhy.cloudfront.net/eyJidWNr...</td>\n",
       "      <td>The Bruery - Where Is the Lava?</td>\n",
       "      <td>The Bruery</td>\n",
       "      <td>wild / sour beer</td>\n",
       "      <td>SaveurBiere</td>\n",
       "      <td>19,90€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>738</td>\n",
       "      <td>https://d33za54wpumlhy.cloudfront.net/eyJidWNr...</td>\n",
       "      <td>To Øl x Casey - Through the Eyes of Mortals</td>\n",
       "      <td>To Øl</td>\n",
       "      <td>wild / sour beer</td>\n",
       "      <td>SaveurBiere</td>\n",
       "      <td>16,50€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>739</td>\n",
       "      <td>https://d33za54wpumlhy.cloudfront.net/eyJidWNr...</td>\n",
       "      <td>The Bruery - So Happens It's Tuesday 2021</td>\n",
       "      <td>The Bruery</td>\n",
       "      <td>imperial stout</td>\n",
       "      <td>SaveurBiere</td>\n",
       "      <td>14,30€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>740</td>\n",
       "      <td>https://d33za54wpumlhy.cloudfront.net/eyJidWNr...</td>\n",
       "      <td>Brooklyn x Russian River - Refraction</td>\n",
       "      <td>Brooklyn Brewery</td>\n",
       "      <td>wild / sour beer</td>\n",
       "      <td>SaveurBiere</td>\n",
       "      <td>24,90€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>741</td>\n",
       "      <td>https://d33za54wpumlhy.cloudfront.net/eyJidWNr...</td>\n",
       "      <td>Thornbridge Barden</td>\n",
       "      <td>Thornbridge Brewery</td>\n",
       "      <td>English Pale Ale</td>\n",
       "      <td>SaveurBiere</td>\n",
       "      <td>3,30€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1463 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              index_scrapping  \\\n",
       "unique_index                    \n",
       "0                           0   \n",
       "1                           1   \n",
       "2                           2   \n",
       "3                           3   \n",
       "4                           4   \n",
       "...                       ...   \n",
       "1458                      737   \n",
       "1459                      738   \n",
       "1460                      739   \n",
       "1461                      740   \n",
       "1462                      741   \n",
       "\n",
       "                                                     link_photo  \\\n",
       "unique_index                                                      \n",
       "0             https://media.auchan.fr/MEDIASTEP80202553_230x...   \n",
       "1             https://media.auchan.fr/MEDIASTEP157309628_230...   \n",
       "2             https://media.auchan.fr/MEDIASTEP66806491_230x...   \n",
       "3             https://media.auchan.fr/MEDIASTEP137932992_230...   \n",
       "4             https://media.auchan.fr/MEDIASTEP157260428_230...   \n",
       "...                                                         ...   \n",
       "1458          https://d33za54wpumlhy.cloudfront.net/eyJidWNr...   \n",
       "1459          https://d33za54wpumlhy.cloudfront.net/eyJidWNr...   \n",
       "1460          https://d33za54wpumlhy.cloudfront.net/eyJidWNr...   \n",
       "1461          https://d33za54wpumlhy.cloudfront.net/eyJidWNr...   \n",
       "1462          https://d33za54wpumlhy.cloudfront.net/eyJidWNr...   \n",
       "\n",
       "                                                     name  \\\n",
       "unique_index                                                \n",
       "0                                Bière blonde 11,8% boîte   \n",
       "1                        Bière blonde bio 7.2% bouteilles   \n",
       "2                        Bière blonde triple 8% bouteille   \n",
       "3                   Bière brassin de Noël 6,5% bouteilles   \n",
       "4                      Bière blonde triple signature 8.5%   \n",
       "...                                                   ...   \n",
       "1458                      The Bruery - Where Is the Lava?   \n",
       "1459          To Øl x Casey - Through the Eyes of Mortals   \n",
       "1460            The Bruery - So Happens It's Tuesday 2021   \n",
       "1461                Brooklyn x Russian River - Refraction   \n",
       "1462                                   Thornbridge Barden   \n",
       "\n",
       "                            brand              type      website   price  \n",
       "unique_index                                                              \n",
       "0                       BELZEBUTH               NaN       Auchan     NaN  \n",
       "1                      LA GOUDALE               NaN       Auchan     NaN  \n",
       "2               SECRET DES MOINES               NaN       Auchan     NaN  \n",
       "3                      GRIMBERGEN               NaN       Auchan     NaN  \n",
       "4                           CH'TI               NaN       Auchan     NaN  \n",
       "...                           ...               ...          ...     ...  \n",
       "1458                   The Bruery  wild / sour beer  SaveurBiere  19,90€  \n",
       "1459                        To Øl  wild / sour beer  SaveurBiere  16,50€  \n",
       "1460                   The Bruery    imperial stout  SaveurBiere  14,30€  \n",
       "1461             Brooklyn Brewery  wild / sour beer  SaveurBiere  24,90€  \n",
       "1462          Thornbridge Brewery  English Pale Ale  SaveurBiere   3,30€  \n",
       "\n",
       "[1463 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bieres = pd.read_csv(\"scraping/data_beers.csv\",sep=\";\")\n",
    "bieres.columns = ['unique_id','index_scrapping','link_photo','name','brand','type','website','price']\n",
    "bieres.drop(\"unique_id\", inplace=True, axis=1)\n",
    "bieres.rename_axis(index=\"unique_index\", axis=1)"
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:model.ipynb
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "marques = bieres.groupby(\"brand\").all().reset_index()\n",
    "marques.drop([\"index_scrapping\",\"link_photo\",\"name\",\"type\",\"website\",\"price\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
=======
   "execution_count": 4,
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD:model.ipynb
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Fonteinen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 MONTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Noses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB InBev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Weltenburger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Whiplash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Wicked Weed Brewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Yeastie Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>ZooBrew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand\n",
       "0                   1664\n",
       "1            3 Fonteinen\n",
       "2                3 MONTS\n",
       "3                4 Noses\n",
       "4               AB InBev\n",
       "..                   ...\n",
       "346         Weltenburger\n",
       "347             Whiplash\n",
       "348  Wicked Weed Brewing\n",
       "349         Yeastie Boys\n",
       "350              ZooBrew\n",
       "\n",
       "[351 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
=======
      "text/plain": [
       "_StoreAction(option_strings=['-c', '--confidence'], dest='confidence', nargs=None, const=None, default=0.2, type=<class 'float'>, choices=None, help='minimum probability to filter weak detections', metavar=None)"
      ]
     },
     "execution_count": 4,
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD:model.ipynb
    "marques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification des bières\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate cs_td2\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
=======
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True, help=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True, help=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.2, help=\"minimum probability to filter weak detections\")\n",
    "#args = vars(ap.parse_args())"
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des images pour les modèles pré-entraînés PyTorch\n",
    "# voir: https://pytorch.org/docs/stable/torchvision/models.html\n",
    "# et ici pour les « explications » sur les valeurs exactes: https://github.com/pytorch/vision/issues/1439\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD:model.ipynb
    "# on lit une première fois les images du dataset\n",
    "# TODO adapter le path selon l'endroit où sont stockées les données\n",
    "image_directory = \"./scraping/data/images\"\n",
    "dataset_full = datasets.ImageFolder(image_directory, data_transforms)"
=======
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect, then generate a set of bounding box colors for each class\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "\t\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "\t\"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "\t\"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))"
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:model.ipynb
   "execution_count": null,
=======
   "execution_count": 4,
>>>>>>> bb823e6431420afb10587f157804197770add4e4:bottle_detection/model.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images de train : 252\n",
      "Nombre d'images de val : 63\n",
      "Nombre d'images de test : 105\n"
     ]
    }
   ],
   "source": [
    "# on split en train, val et test à partir de la liste complète\n",
    "np.random.seed(42)\n",
    "samples_train, samples_test = train_test_split(dataset_full.samples)\n",
    "samples_train, samples_val = train_test_split(samples_train,test_size=0.2)\n",
    "\n",
    "print(\"Nombre d'images de train : %i\" % len(samples_train))\n",
    "print(\"Nombre d'images de val : %i\" % len(samples_val))\n",
    "print(\"Nombre d'images de test : %i\" % len(samples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19e425ecb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on définit les datasets et loaders pytorch à partir des listes d'images de train / val / test\n",
    "dataset_train = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_train.samples = samples_train\n",
    "dataset_train.imgs = samples_train\n",
    "loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "dataset_val = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_val.samples = samples_val\n",
    "dataset_val.imgs = samples_val\n",
    "\n",
    "dataset_test = datasets.ImageFolder(image_directory, data_transforms)\n",
    "dataset_test.samples = samples_test\n",
    "dataset_test.imgs = samples_test\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apprentissage sur 6 classes\n"
     ]
    }
   ],
   "source": [
    "# détermination du nombre de classes (nb_classes=6)\n",
    "# vérification que les labels sont bien dans [0, nb_classes]\n",
    "labels=[x[1] for x in samples_train]\n",
    "if np.min(labels) != 0:\n",
    "    print(\"Error: labels should start at 0 (min is %i)\" % np.min(labels))\n",
    "    sys.exit(-1)\n",
    "if np.max(labels) != (len(np.unique(labels))-1):\n",
    "    print(\"Error: labels should go from 0 to Nclasses (max label = {}; Nclasse = {})\".format(np.max(labels),len(np.unique(labels)))  )\n",
    "    sys.exit(-1)\n",
    "nb_classes = np.max(labels)+1\n",
    "# nb_classes = len(dataset_train.classes)\n",
    "print(\"Apprentissage sur {} classes\".format(nb_classes))\n",
    "\n",
    "# on utilisera le GPU (beaucoup plus rapide) si disponible, sinon on utilisera le CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # forcer en CPU s'il y a des problèmes de mémoire GPU (+ être patient...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit une fonction d'évaluation\n",
    "def evaluate(model, dataset):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        n_correct = torch.sum(preds == labels)\n",
    "        \n",
    "        avg_loss += loss.item()\n",
    "        avg_accuracy += n_correct\n",
    "        \n",
    "    return avg_loss / len(dataset), float(avg_accuracy) / len(dataset)\n",
    "\n",
    "# fonction classique d'entraînement d'un modèle, voir TDs précédents\n",
    "PRINT_LOSS = True\n",
    "def train_model(model, loader_train, data_val, optimizer, criterion, n_epochs=10):\n",
    "    for epoch in range(n_epochs): # à chaque epochs\n",
    "        print(\"EPOCH % i\" % epoch)\n",
    "        for i, data in enumerate(loader_train): # itère sur les minibatchs via le loader apprentissage\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # on passe les données sur CPU / GPU\n",
    "            optimizer.zero_grad() # on réinitialise les gradients\n",
    "            outputs = model(inputs) # on calcule l'output\n",
    "            \n",
    "            loss = criterion(outputs, labels) # on calcule la loss\n",
    "            if PRINT_LOSS:\n",
    "                model.train(False)\n",
    "                loss_val, accuracy = evaluate(model, data_val)\n",
    "                model.train(True)\n",
    "                print(\"{} loss train: {:1.4f}\\t val {:1.4f}\\tAcc (val): {:.1%}\".format(i, loss.item(), loss_val, accuracy   ))\n",
    "            \n",
    "            loss.backward() # on effectue la backprop pour calculer les gradients\n",
    "            optimizer.step() # on update les gradients en fonction des paramètres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération du ResNet-18 pré-entraîné...\n",
      "Apprentissage en transfer learning\n",
      "EPOCH  0\n",
      "0 loss train: 1.8596\t val 0.1204\tAcc (val): 19.0%\n",
      "1 loss train: 2.0103\t val 0.1198\tAcc (val): 19.0%\n",
      "2 loss train: 1.8643\t val 0.1186\tAcc (val): 17.5%\n",
      "3 loss train: 1.8388\t val 0.1170\tAcc (val): 19.0%\n",
      "4 loss train: 1.7657\t val 0.1161\tAcc (val): 14.3%\n",
      "5 loss train: 1.8263\t val 0.1160\tAcc (val): 19.0%\n",
      "6 loss train: 1.8594\t val 0.1161\tAcc (val): 23.8%\n",
      "7 loss train: 1.8043\t val 0.1161\tAcc (val): 20.6%\n",
      "EPOCH  1\n",
      "0 loss train: 1.8369\t val 0.1159\tAcc (val): 20.6%\n",
      "1 loss train: 1.7574\t val 0.1153\tAcc (val): 22.2%\n",
      "2 loss train: 1.6485\t val 0.1154\tAcc (val): 23.8%\n",
      "3 loss train: 1.7914\t val 0.1151\tAcc (val): 27.0%\n",
      "4 loss train: 1.6787\t val 0.1146\tAcc (val): 27.0%\n",
      "5 loss train: 1.6996\t val 0.1132\tAcc (val): 27.0%\n",
      "6 loss train: 1.7239\t val 0.1110\tAcc (val): 30.2%\n",
      "7 loss train: 1.6817\t val 0.1082\tAcc (val): 33.3%\n",
      "EPOCH  2\n",
      "0 loss train: 1.5082\t val 0.1059\tAcc (val): 39.7%\n",
      "1 loss train: 1.5673\t val 0.1038\tAcc (val): 39.7%\n",
      "2 loss train: 1.6089\t val 0.1020\tAcc (val): 38.1%\n",
      "3 loss train: 1.5006\t val 0.1006\tAcc (val): 38.1%\n",
      "4 loss train: 1.5044\t val 0.0993\tAcc (val): 39.7%\n",
      "5 loss train: 1.5015\t val 0.0983\tAcc (val): 42.9%\n",
      "6 loss train: 1.5474\t val 0.0973\tAcc (val): 41.3%\n",
      "7 loss train: 1.4209\t val 0.0961\tAcc (val): 44.4%\n",
      "EPOCH  3\n",
      "0 loss train: 1.3790\t val 0.0950\tAcc (val): 44.4%\n",
      "1 loss train: 1.3780\t val 0.0938\tAcc (val): 46.0%\n",
      "2 loss train: 1.4439\t val 0.0927\tAcc (val): 46.0%\n",
      "3 loss train: 1.2760\t val 0.0923\tAcc (val): 46.0%\n",
      "4 loss train: 1.2929\t val 0.0919\tAcc (val): 47.6%\n",
      "5 loss train: 1.4337\t val 0.0917\tAcc (val): 50.8%\n",
      "6 loss train: 1.2075\t val 0.0908\tAcc (val): 52.4%\n",
      "7 loss train: 1.3541\t val 0.0902\tAcc (val): 55.6%\n",
      "EPOCH  4\n",
      "0 loss train: 1.2881\t val 0.0887\tAcc (val): 55.6%\n",
      "1 loss train: 1.2556\t val 0.0879\tAcc (val): 57.1%\n",
      "2 loss train: 1.1037\t val 0.0871\tAcc (val): 57.1%\n",
      "3 loss train: 1.2538\t val 0.0857\tAcc (val): 58.7%\n",
      "4 loss train: 1.0889\t val 0.0848\tAcc (val): 58.7%\n",
      "5 loss train: 1.1575\t val 0.0837\tAcc (val): 61.9%\n",
      "6 loss train: 1.2575\t val 0.0833\tAcc (val): 58.7%\n",
      "7 loss train: 1.3527\t val 0.0827\tAcc (val): 57.1%\n",
      "EPOCH  5\n",
      "0 loss train: 1.2172\t val 0.0811\tAcc (val): 57.1%\n",
      "1 loss train: 1.1467\t val 0.0801\tAcc (val): 58.7%\n",
      "2 loss train: 1.0601\t val 0.0791\tAcc (val): 58.7%\n",
      "3 loss train: 1.0136\t val 0.0782\tAcc (val): 58.7%\n",
      "4 loss train: 1.0488\t val 0.0769\tAcc (val): 60.3%\n",
      "5 loss train: 1.0237\t val 0.0760\tAcc (val): 60.3%\n",
      "6 loss train: 1.0744\t val 0.0754\tAcc (val): 60.3%\n",
      "7 loss train: 1.0072\t val 0.0747\tAcc (val): 60.3%\n",
      "EPOCH  6\n",
      "0 loss train: 0.9550\t val 0.0744\tAcc (val): 60.3%\n",
      "1 loss train: 0.9429\t val 0.0738\tAcc (val): 60.3%\n",
      "2 loss train: 0.9715\t val 0.0736\tAcc (val): 60.3%\n",
      "3 loss train: 0.9252\t val 0.0731\tAcc (val): 61.9%\n",
      "4 loss train: 1.1145\t val 0.0725\tAcc (val): 60.3%\n",
      "5 loss train: 0.9618\t val 0.0724\tAcc (val): 60.3%\n",
      "6 loss train: 0.9639\t val 0.0720\tAcc (val): 63.5%\n",
      "7 loss train: 0.9469\t val 0.0710\tAcc (val): 63.5%\n",
      "EPOCH  7\n",
      "0 loss train: 0.9614\t val 0.0706\tAcc (val): 66.7%\n",
      "1 loss train: 0.9223\t val 0.0696\tAcc (val): 65.1%\n",
      "2 loss train: 0.8458\t val 0.0691\tAcc (val): 65.1%\n",
      "3 loss train: 0.9305\t val 0.0692\tAcc (val): 65.1%\n",
      "4 loss train: 0.8820\t val 0.0691\tAcc (val): 65.1%\n",
      "5 loss train: 0.8501\t val 0.0687\tAcc (val): 66.7%\n",
      "6 loss train: 0.7436\t val 0.0685\tAcc (val): 66.7%\n",
      "7 loss train: 0.8797\t val 0.0676\tAcc (val): 66.7%\n",
      "EPOCH  8\n",
      "0 loss train: 0.7142\t val 0.0675\tAcc (val): 68.3%\n",
      "1 loss train: 0.8754\t val 0.0676\tAcc (val): 68.3%\n",
      "2 loss train: 0.8598\t val 0.0672\tAcc (val): 69.8%\n",
      "3 loss train: 0.9083\t val 0.0669\tAcc (val): 68.3%\n",
      "4 loss train: 0.7289\t val 0.0667\tAcc (val): 68.3%\n",
      "5 loss train: 0.7846\t val 0.0667\tAcc (val): 68.3%\n",
      "6 loss train: 0.8735\t val 0.0662\tAcc (val): 68.3%\n",
      "7 loss train: 0.8772\t val 0.0650\tAcc (val): 66.7%\n",
      "EPOCH  9\n",
      "0 loss train: 0.6914\t val 0.0642\tAcc (val): 66.7%\n",
      "1 loss train: 0.8075\t val 0.0636\tAcc (val): 66.7%\n",
      "2 loss train: 0.7603\t val 0.0629\tAcc (val): 68.3%\n",
      "3 loss train: 0.8079\t val 0.0626\tAcc (val): 68.3%\n",
      "4 loss train: 0.7913\t val 0.0618\tAcc (val): 65.1%\n",
      "5 loss train: 0.7868\t val 0.0615\tAcc (val): 68.3%\n",
      "6 loss train: 0.6709\t val 0.0615\tAcc (val): 69.8%\n",
      "7 loss train: 0.8376\t val 0.0615\tAcc (val): 68.3%\n",
      "Accuracy (test): 74.3%\n"
     ]
    }
   ],
   "source": [
    "# Récupérer un réseau pré-entraîné (resnet-18)\n",
    "print(\"Récupération du ResNet-18 pré-entraîné...\")\n",
    "my_net = models.resnet18(pretrained=True)\n",
    "\n",
    "#===== Transfer learning \"simple\" (sans fine tuning) =====\n",
    "\n",
    "# on indique qu'il est inutile de calculer les gradients des paramètres du réseau\n",
    "for param in my_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# on remplace la dernière couche fully connected à 1000 sorties (classes d'ImageNet) par une fully connected à 6 sorties (nos classes).\n",
    "# par défaut, les gradients des paramètres cette couche seront bien calculés\n",
    "my_net.fc = nn.Linear(in_features=my_net.fc.in_features, out_features=nb_classes, bias=True)\n",
    "# on pourrait aussi réinitaliser d'autres couches telle: my_net.layer4[1].conv2\n",
    "#  NB: par défaut, la couche réinitialisée a .requires_grad=True\n",
    "\n",
    "my_net.to(device) # on utilise le GPU / CPU en fonction de ce qui est disponible\n",
    "my_net.train(True) # pas indispensable ici, mais bonne pratique de façon générale\n",
    "                   # permet notamment d'activer / désactiver le dropout selon qu'on entraîne ou teste le modèle\n",
    "\n",
    "# on définit une loss et un optimizer\n",
    "# on limite l'optimisation aux paramètres de la nouvelle couche\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_net.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print(\"Apprentissage en transfer learning\")\n",
    "my_net.train(True)\n",
    "torch.manual_seed(42)\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n",
    "\n",
    "# évaluation\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test)\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#===== Fine tuning =====\n",
    "\n",
    "# on réinitialise resnet\n",
    "my_net = models.resnet18(pretrained=True)\n",
    "my_net.fc = nn.Linear(in_features=my_net.fc.in_features, out_features=nb_classes, bias=True)\n",
    "my_net.to(device)\n",
    "\n",
    "# cette fois on veut updater tous les paramètres\n",
    "params_to_update = my_net.parameters()\n",
    "\n",
    "# il est possible de ne sélectionner que quelques couches\n",
    "#     (plutôt parmi les \"dernières\", proches de la loss)\n",
    "#    Exemple (dans ce cas, oter \"params_to_update = my_net.parameters()\") ci-dessus\n",
    "# list_of_layers_to_finetune=['fc.weight','fc.bias','layer4.1.conv2.weight','layer4.1.bn2.bias','layer4.1.bn2.weight']\n",
    "# params_to_update=[]\n",
    "# for name,param in my_net.named_parameters():\n",
    "#     if name in list_of_layers_to_finetune:\n",
    "#         print(\"fine tune \",name)\n",
    "#         params_to_update.append(param)\n",
    "#         param.requires_grad = True\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "\n",
    "# on ré-entraîne\n",
    "print(\"Apprentissage avec fine-tuning\")\n",
    "my_net.train(True)\n",
    "torch.manual_seed(42)\n",
    "train_model(my_net, loader_train, dataset_val, optimizer, criterion, n_epochs=10)\n",
    "\n",
    "# on ré-évalue les performances\n",
    "my_net.train(False)\n",
    "loss, accuracy = evaluate(my_net, dataset_test)\n",
    "print(\"Accuracy (test): %.1f%%\" % (100 * accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
